<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="PRBench: A Physical Reasoning Benchmark for Robotics">
    <title>PRBench: A Physical Reasoning Benchmark for Robotics</title>
    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
</head>
<body>
    <div class="draft-banner">
        EARLY DRAFT: DO NOT DISTRIBUTE
    </div>
    <header>
        <nav>
            <div class="container">
                <h1>PRBench: A Physical Reasoning Benchmark for Robotics</h1>
                <ul class="nav-links">
                    <li><a href="#about">About</a></li>
                    <li><a href="#usage">Usage</a></li>
                    <li><a href="#benchmark">Environments</a></li>
                    <li><a href="#results">Results</a></li>
                    <li><a href="#acknowledgements">Acknowledgements</a></li>
                </ul>
            </div>
        </nav>
    </header>

    <main>
        <section class="title-authors-section">
            <div class="container">
                <h1>PRBench: A Physical Reasoning Benchmark for Robotics</h1>
                
                <div class="authors-list">
                    <div class="author">
                        <span class="author-name">Yixuan Huang*</span>
                        <span class="author-affiliation">Princeton</span>
                    </div>
                    <div class="author">
                        <span class="author-name">Bowen Li*</span>
                        <span class="author-affiliation">CMU</span>
                    </div>
                    <div class="author">
                        <span class="author-name">Vaibhav Saxena*</span>
                        <span class="author-affiliation">Georgia Tech</span>
                    </div>
                    <div class="author-break"></div>
                    <div class="author">
                        <span class="author-name">Utkarsh Mishra</span>
                        <span class="author-affiliation">Georgia Tech</span>
                    </div>
                    <div class="author">
                        <span class="author-name">Yichao Liang</span>
                        <span class="author-affiliation">Cambridge</span>
                    </div>
                    <div class="author">
                        <span class="author-name">Danfei Xu</span>
                        <span class="author-affiliation">Georgia Tech</span>
                    </div>
                    <div class="author">
                        <span class="author-name">Tom Silver</span>
                        <span class="author-affiliation">Princeton</span>
                    </div>
                </div>
                
                <p class="equal-contribution">*Equal contribution</p>
            </div>
        </section>

        <section id="hero">
            <div class="container">
                <div class="demo-showcase">
                    <div class="demo-gif-grid">
                        <a href="environments/clutteredretrieval2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/ClutteredRetrieval2D.gif" alt="ClutteredRetrieval2D Demo">
                            <span class="demo-label">ClutteredRetrieval2D</span>
                        </a>
                        <a href="environments/motion2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/Motion2D.gif" alt="Motion2D Demo">
                            <span class="demo-label">Motion2D</span>
                        </a>
                        <a href="environments/obstruction2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/Obstruction2D.gif" alt="Obstruction2D Demo">
                            <span class="demo-label">Obstruction2D</span>
                        </a>
                        <a href="environments/pushpullhook2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/PushPullHook2D.gif" alt="PushPullHook2D Demo">
                            <span class="demo-label">PushPullHook2D</span>
                        </a>
                        <a href="environments/dynobstruction2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/DynObstruction2D.gif" alt="DynObstruction2D Demo">
                            <span class="demo-label">DynObstruction2D</span>
                        </a>
                        <a href="environments/clutteredstorage2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/ClutteredStorage2D.gif" alt="ClutteredStorage2D Demo">
                            <span class="demo-label">ClutteredStorage2D</span>
                        </a>
                        <a href="environments/dynpushpullhook2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/DynPushPullHook2D.gif" alt="DynPushPullHook2D Demo">
                            <span class="demo-label">DynPushPullHook2D</span>
                        </a>
                        <a href="environments/dynpusht2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/DynPushT2D.gif" alt="DynPushT2D Demo">
                            <span class="demo-label">DynPushT2D</span>
                        </a>
                        <a href="environments/dynscooppour-group.html" class="demo-gif-item">
                            <img src="hero-gifs/DynScoopPour2D.gif" alt="DynScoopPour2D Demo">
                            <span class="demo-label">DynScoopPour2D</span>
                        </a>
                        <a href="environments/stickbutton2d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/StickButton2D.gif" alt="StickButton2D Demo">
                            <span class="demo-label">StickButton2D</span>
                        </a>
                        <a href="environments/motion3d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/ArmMotion3D.gif" alt="ArmMotion3D Demo">
                            <span class="demo-label">ArmMotion3D</span>
                        </a>
                        <a href="environments/obstruction3d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/Obstruction3D.gif" alt="Obstruction3D Demo">
                            <span class="demo-label">Obstruction3D</span>
                        </a>
                        <a href="environments/packing3d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/Packing3D.gif" alt="Packing3D Demo">
                            <span class="demo-label">Packing3D</span>
                        </a>
                        <a href="environments/basemotion3d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/BaseMotion3D.gif" alt="BaseMotion3D Demo">
                            <span class="demo-label">BaseMotion3D</span>
                        </a>
                        <a href="environments/constrainedcupboard3d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/ConstrainedCupboard3D.gif" alt="ConstrainedCupboard3D Demo">
                            <span class="demo-label">ConstrainedCupboard3D</span>
                        </a>
                        <a href="environments/sortclutteredblocks3d-group.html" class="demo-gif-item">
                            <img src="hero-gifs/SortClutteredBlocks3D.gif" alt="SortClutteredBlocks3D Demo">
                            <span class="demo-label">SortClutteredBlocks3D</span>
                        </a>
                    </div>
                </div>
            </div>
        </section>

        <section id="about">
            <div class="container">
                <h2>About PRBench</h2>
                <p class="intro-text">A <strong>p</strong>hysical <strong>r</strong>easoning <strong>bench</strong>mark for robotics.</p>
                
                <div class="about-content">
                    <p>This is a work in progress! We are sharing it with you to get feedback so that we can determine how to focus our next efforts. Thanks for your help!</p>

                    <p>PRBench is designed to test "mid-level" robot reasoning. Existing benchmarks focus on either high-level semantic understanding and task planning ("put the apple on a plate"), or low-level perception and manipulation (pixels to torques). PRBench instead considers the challenges that arise when these two levels meet: to put the apple on a plate, the robot may need to first retrieve a plate from a cupboard ("oh wait, the cupboard is closed -- let me open it first; I need to find a reachable grasp of the cupboard doorknob such that I can then swing open the door without colliding my arm into the adjacent shelf; the plates are blocked by cups, perhaps I can gently push them out of the way..."). In general, these are tasks that feature:</p>
                    <ul>
                        <li>Tight constraints (kinematic, dynamic, collision, etc.)</li>
                        <li>Varying numbers of objects</li>
                        <li>Long time horizons</li>
                        <li>Sparse rewards</li>
                        <li>Diverse task distributions, requiring generalization</li>
                        <li>Challenges inspired by the task-and-motion-planning (TAMP) literature</li>
                    </ul>

                    <p>PRBench is implemented as a collection of Gymnasium environments. Performance is evaluated based on not only evaluate task performance (rewards), but also training time and sample complexity (for data-driven approaches) and evaluation time (especially for planning-based approaches). Our goal is to facilitate direct comparisons between many different approaches, evaluating and supporting progress in the state of the art for robot physical reasoning.</p>

                </div>

                <h3 class="collapsible-header" onclick="toggleCollapsible('challenges-section')">
                    What Makes PRBench Challenging? <span class="toggle-icon" id="challenges-toggle">▼</span>
                </h3>
                
                <div class="collapsible-content" id="challenges-section">
                    <div class="challenges-grid">
                        <div class="challenge-card">
                            <h4>For Reinforcement Learning</h4>
                            <p>Environments have long horizons and sparse rewards. Users are welcome to engineer dense rewards, but doing so may be nontrivial. Environments also have very diverse task distributions, so learned policies must generalize.</p>
                        </div>
                        
                        <div class="challenge-card">
                            <h4>For Imitation Learning</h4>
                            <p>As with RL, generalization across tasks is a major challenge. Furthermore, we supply some demonstrations, but they are typically suboptimal, multimodal, and limited in quantity.</p>
                        </div>
                        
                        <div class="challenge-card">
                            <h4>For Language Models</h4>
                            <p>The physical reasoning required in PRBench is not easy to represent in natural language. The tasks in PRBench are designed to test "mid-level" physical reasoning, between language and vision.</p>
                        </div>
                        
                        <div class="challenge-card">
                            <h4>For Hierarchical Approaches</h4>
                            <p>Approaches that first decide "what to do" and then decide "how to do it" will run into difficulties when there are couplings between these high-level and low-level decisions.</p>
                        </div>
                        
                        <div class="challenge-card">
                            <h4>For Task and Motion Planning</h4>
                            <p>PRBench does not provide any models for TAMP. Users are welcome to engineer their own, but doing so may be nontrivial. Some environments contain many objects, which may make planning slow.</p>
                        </div>

                        <div class="challenge-card">
                            <h4>For Human Engineers</h4>
                            <p>PRBench features diverse task distributions and long time horizons, making it challenging for engineers to hand-design even very environment-specific solutions. A single task may be straightforward, but designing generalized solutions is nontrivial.</p>
                        </div>
                    </div>
                </div>

                <h3 class="collapsible-header" onclick="toggleCollapsible('unique-section')">
                    What Makes PRBench Unique? <span class="toggle-icon" id="unique-toggle">▼</span>
                </h3>
                
                <div class="collapsible-content" id="unique-section">
                    <div class="comparison-table-wrapper">
                        <table class="comparison-table">
                            <thead>
                                <tr>
                                    <th>Benchmarks</th>
                                    <th>Physics?</th>
                                    <th>Reasoning (Generalize)</th>
                                    <th>Long-horizon (&gt;500)</th>
                                    <th>Robotics-Oriented</th>
                                    <th>Semanticless (non-language constraints)</th>
                                    <th>Unified 2D & 3D</th>
                                    <th>Multi-Object Physical Contacts? (&gt;5)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Atari Games [1]</td>
                                    <td>❌</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>2D</td>
                                    <td>❌</td>
                                </tr>
                                <tr>
                                    <td>DM-Control [2]</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>3D</td>
                                    <td>❌</td>
                                </tr>
                                <tr>
                                    <td>MineDojo [3]</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>❌</td>
                                </tr>
                                <tr>
                                    <td>CALVIN [4]</td>
                                    <td>❓</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>✅</td>
                                </tr>
                                <tr>
                                    <td>LIBERO [5]</td>
                                    <td>❓</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>✅</td>
                                </tr>
                                <tr>
                                    <td>LogiCity [6]</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>2D</td>
                                    <td>❌</td>
                                </tr>
                                <tr>
                                    <td>Embodied Agent Interface [7]</td>
                                    <td>❓</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>❌</td>
                                </tr>
                                <tr>
                                    <td>OGBench [8]</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>❌</td>
                                </tr>
                                <tr>
                                    <td>BEHAVIOR-1k [9]</td>
                                    <td>❓</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>❌</td>
                                </tr>
                                <tr>
                                    <td>RoboCasa [10]</td>
                                    <td>❓</td>
                                    <td>❌</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>❓</td>
                                </tr>
                                <tr>
                                    <td>Embodied Bench [11]</td>
                                    <td>❓</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>❓</td>
                                </tr>
                                <tr>
                                    <td>ManiSkill-HAB [12]</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❓</td>
                                    <td>3D</td>
                                    <td>✅</td>
                                </tr>
                                <tr>
                                    <td>Furniturebench [13]</td>
                                    <td>❌(Real)</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>Real</td>
                                    <td>✅</td>
                                </tr>
                                <tr>
                                    <td>VLABench [14]</td>
                                    <td>❓</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>❌</td>
                                    <td>3D</td>
                                    <td>✅</td>
                                </tr>
                                <tr class="highlight-row">
                                    <td><strong>PRBench (Ours)</strong></td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>✅</td>
                                    <td>2D&3D</td>
                                    <td>✅</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                    
                    <div class="references">
                        <p><small>[1] Machado et al. "Revisiting the arcade learning environment." <em>JAIR</em> 61 (2018).</small></p>
                        <p><small>[2] Tassa et al. "Deepmind control suite." <em>arXiv:1801.00690</em> (2018).</small></p>
                        <p><small>[3] Fan et al. "Minedojo: Building open-ended embodied agents with internet-scale knowledge." <em>NeurIPS</em> 35 (2022).</small></p>
                        <p><small>[4] Mees et al. "Calvin: A benchmark for language-conditioned policy learning." <em>IEEE RA-L</em> 7.3 (2022).</small></p>
                        <p><small>[5] Liu et al. "Libero: Benchmarking knowledge transfer for lifelong robot learning." <em>NeurIPS</em> 36 (2023).</small></p>
                        <p><small>[6] Li et al. "LogiCity: Advancing neuro-symbolic ai with abstract urban simulation." <em>NeurIPS</em> 37 (2024).</small></p>
                        <p><small>[7] Li et al. "Embodied agent interface: Benchmarking llms for embodied decision making." <em>NeurIPS</em> 37 (2024).</small></p>
                        <p><small>[8] Park et al. "OGBench: Benchmarking Offline Goal-Conditioned RL." <em>ICLR</em> (2025).</small></p>
                        <p><small>[9] Li et al. "Behavior-1k: A benchmark for embodied ai with 1,000 everyday activities." <em>CoRL</em> (2023).</small></p>
                        <p><small>[10] Nasiriany et al. "RoboCasa: Large-Scale Simulation of Everyday Tasks." <em>RSS 2024 Workshop</em>.</small></p>
                        <p><small>[11] Yang et al. "EmbodiedBench: Comprehensive Benchmarking Multi-modal LLMs." <em>ICML</em> (2024).</small></p>
                        <p><small>[12] Shukla et al. "ManiSkill-HAB: A Benchmark for Low-Level Manipulation." <em>ICLR</em> (2025).</small></p>
                        <p><small>[13] Heo et al. "Furniturebench: Reproducible real-world benchmark." <em>IJRR</em> 44.10-11 (2025).</small></p>
                        <p><small>[14] Zhang et al. "Vlabench: A large-scale benchmark for language-conditioned robotics." <em>ICCV</em> (2025).</small></p>
                    </div>
                </div>
            </div>
        </section>

                                                                                                                        <section id="usage">
            <div class="container">
                <h2>Usage</h2>
                
                <h3>Installation</h3>
                <p>We strongly recommend <a href="https://docs.astral.sh/uv/getting-started/installation/" target="_blank">uv</a>. Then choose one of the following based on your needs:</p>
                
                <div class="code-block">
                    <pre><code class="language-bash"># Core dependencies only
uv pip install -r optional_prpl_requirements/core.txt && uv pip install -e .

# Everything (excluding develop)
uv pip install -e ".[all]"

# Specific environments
uv pip install -e ".[geom2d]"      # Geometric 2D only
uv pip install -e ".[dynamic2d]"   # Dynamic 2D only
uv pip install -e ".[geom3d]"      # Geometric 3D only
uv pip install -e ".[tidybot]"     # TidyBot only

# Compositional
uv pip install -e ".[geom2d,geom3d]"</code></pre>
                </div>

                <h3>Basic Usage (Gym API)</h3>
                <div class="code-block">
                    <pre><code class="language-python">import prbench
prbench.register_all_environments()
env = prbench.make("prbench/Obstruction2D-o3-v0")  # 3 obstructions
obs, info = env.reset()  # procedural generation
action = env.action_space.sample()
next_obs, reward, terminated, truncated, info = env.step(action)
img = env.render()</code></pre>
                </div>

                <h3 class="collapsible-header" onclick="toggleCollapsible('object-centric-section')">
                    Object-Centric States <span class="toggle-icon" id="object-centric-toggle">▼</span>
                </h3>
                
                <div class="collapsible-content" id="object-centric-section">
                    <p>All environments in PRBench use object-centric states:</p>
                    
                    <div class="code-block">
                        <pre><code class="language-python">from prbench.envs.geom2d.obstruction2d import ObjectCentricObstruction2DEnv
env = ObjectCentricObstruction2DEnv(num_obstructions=3)
obs, _ = env.reset(seed=123)
print(obs.pretty_str())</code></pre>
                    </div>

                    <p>Here, <code>obs</code> is an <a href="https://github.com/tomsilver/relational-structs/blob/main/src/relational_structs/object_centric_state.py#L25" target="_blank">ObjectCentricState</a>, and the printout is:</p>
                    
                    <div class="code-block">
                        <pre><code>############################################################### STATE ###############################################################
type: crv_robot           x         y    theta    base_radius    arm_joint    arm_length    vacuum    gripper_height    gripper_width
-----------------  --------  --------  -------  -------------  -----------  ------------  --------  ----------------  ---------------
robot              0.885039  0.803795  -1.5708            0.1          0.1           0.2         0              0.07             0.01

type: rectangle           x         y    theta    static    color_r    color_g    color_b    z_order      width     height
-----------------  --------  --------  -------  --------  ---------  ---------  ---------  ---------  ---------  ---------
obstruction0       0.422462  0.100001        0         0       0.75        0.1        0.1        100  0.132224   0.0766399
obstruction1       0.804663  0.100001        0         0       0.75        0.1        0.1        100  0.0805652  0.0955062
obstruction2       0.559246  0.100001        0         0       0.75        0.1        0.1        100  0.12608    0.180172

type: target_block          x         y    theta    static    color_r    color_g    color_b    z_order     width    height
--------------------  -------  --------  -------  --------  ---------  ---------  ---------  ---------  --------  --------
target_block          1.20082  0.100001        0         0   0.501961          0   0.501961        100  0.138302  0.155183

type: target_surface           x    y    theta    static    color_r    color_g    color_b    z_order     width    height
----------------------  --------  ---  -------  --------  ---------  ---------  ---------  ---------  --------  --------
target_surface          0.499675    0        0         1   0.501961          0   0.501961        101  0.180286       0.1
#####################################################################################################################################</code></pre>
                    </div>

                    <p>For compatibility with baselines, observations are provided as vectors. Convert between vectors and object-centric states:</p>
                    
                    <div class="code-block">
                        <pre><code class="language-python">import prbench
prbench.register_all_environments()
env = prbench.make("prbench/Obstruction2D-o3-v0")
vec_obs, _ = env.reset(seed=123)
object_centric_obs = env.observation_space.devectorize(vec_obs)
recovered_vec_obs = env.observation_space.vectorize(object_centric_obs)</code></pre>
                    </div>
                </div>
            </div>
        </section>

        <section id="benchmark">
            <div class="container">
                <h2>Environments</h2>
                <p>PRBench contains diverse physical reasoning environments organized into four categories. Click on any environment family to explore variants and details.</p>

                <div class="env-categories-grid">
                    <div class="env-category-card">
                        <h3><a href="environments/geometric-2d.html">Geometric 2D</a></h3>
                        <p class="category-desc">2D environments focused on geometric reasoning and spatial relationships</p>
                        <ul class="env-list">
                            <li><a href="environments/clutteredretrieval2d-group.html">ClutteredRetrieval2D</a> <span class="env-count">3 variants</span></li>
                            <li><a href="environments/motion2d-group.html">Motion2D</a> <span class="env-count">6 variants</span></li>
                            <li><a href="environments/obstruction2d-group.html">Obstruction2D</a> <span class="env-count">5 variants</span></li>
                            <li><a href="environments/pushpullhook2d-group.html">PushPullHook2D</a> <span class="env-count">1 variant</span></li>
                            <li><a href="environments/clutteredstorage2d-group.html">ClutteredStorage2D</a> <span class="env-count">4 variants</span></li>
                            <li><a href="environments/stickbutton2d-group.html">StickButton2D</a> <span class="env-count">5 variants</span></li>
                        </ul>
                    </div>

                    <div class="env-category-card">
                        <h3><a href="environments/geometric-3d.html">Geometric 3D</a></h3>
                        <p class="category-desc">3D environments for testing spatial reasoning in three dimensions</p>
                        <ul class="env-list">
                            <li><a href="environments/motion3d-group.html">Motion3D</a> <span class="env-count">1 variant</span></li>
                            <li><a href="environments/obstruction3d-group.html">Obstruction3D</a> <span class="env-count">5 variants</span></li>
                            <li><a href="environments/packing3d-group.html">Packing3D</a> <span class="env-count">3 variants</span></li>
                        </ul>
                    </div>

                    <div class="env-category-card">
                        <h3><a href="environments/dynamic-2d.html">Dynamic 2D</a></h3>
                        <p class="category-desc">2D environments involving dynamic physical interactions and motion</p>
                        <ul class="env-list">
                            <li><a href="environments/dynobstruction2d-group.html">DynObstruction2D</a> <span class="env-count">5 variants</span></li>
                            <li><a href="environments/dynpushpullhook2d-group.html">DynPushPullHook2D</a> <span class="env-count">3 variants</span></li>
                            <li><a href="environments/dynpusht2d-group.html">DynPushT2D</a> <span class="env-count">1 variant</span></li>
                            <li><a href="environments/dynscooppour2d-group.html">DynScoopPour2D</a> <span class="env-count">4 variants</span></li>
                        </ul>
                    </div>

                    <div class="env-category-card">
                        <h3><a href="environments/dynamic-3d.html">Dynamic 3D</a></h3>
                        <p class="category-desc">3D environments with complex dynamics and physical interactions</p>
                        <ul class="env-list">
                            <li><a href="environments/basemotion3d-group.html">BaseMotion3D</a> <span class="env-count">1 variant</span></li>
                            <li><a href="environments/constrainedcupboard3d-group.html">ConstrainedCupboard3D</a> <span class="env-count">1 variant</span></li>
                            <li><a href="environments/sortclutteredblocks3d-group.html">SortClutteredBlocks3D</a> <span class="env-count">1 variant</span></li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

        <section id="results">
            <div class="container">
                <h2>Very Preliminary Results</h2>
                <p>Success rates on evaluation tasks: mean ± standard deviation across 5 random seeds and 50 evaluation episodes per seed.</p>
                
                <div class="results-table-wrapper">
                    <table class="results-table">
                        <thead>
                            <tr>
                                <th>Environment</th>
                                <th>RL-PPO</th>
                                <th>RL-SAC</th>
                                <th>Diffusion Policy</th>
                                <th>LLM Planning</th>
                                <th>VLM Planning</th>
                                <th>Bilevel Planning</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><a href="environments/motion2d-p0-v0.html">Motion2D-p0-v0</a></td>
                                <td>0.948 ± 0.066</td>
                                <td>0.000 ± 0.000</td>
                                <td>0.964 ± 0.008</td>
                                <td>1.000 ± 0.000</td>
                                <td>1.000 ± 0.000</td>
                                <td>1.000 ± 0.000</td>
                            </tr>
                            <tr>
                                <td><a href="environments/motion2d-p2-v0.html">Motion2D-p2-v0</a></td>
                                <td>0.000 ± 0.000</td>
                                <td>0.000 ± 0.000</td>
                                <td>0.932 ± 0.027</td>
                                <td>0.000 ± 0.000</td>
                                <td>0.000 ± 0.000</td>
                                <td>0.996 ± 0.063</td>
                            </tr>
                            <tr>
                                <td><a href="environments/stickbutton2d-b1-v0.html">StickButton2D-b1-v0</a></td>
                                <td>0.072 ± 0.027</td>
                                <td>0.012 ± 0.011</td>
                                <td>0.652 ± 0.039</td>
                                <td>0.287 ± 0.454</td>
                                <td>0.227 ± 0.420</td>
                                <td>0.992 ± 0.089</td>
                            </tr>
                            <tr>
                                <td><a href="environments/stickbutton2d-b3-v0.html">StickButton2D-b3-v0</a></td>
                                <td>0.000 ± 0.000</td>
                                <td>0.000 ± 0.000</td>
                                <td>0.316 ± 0.061</td>
                                <td>0.007 ± 0.082</td>
                                <td>0.007 ± 0.082</td>
                                <td>0.300 ± 0.459</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <p>We will later add more baselines, run on all environments, and report more metrics. We look forward to feedback about which of these to prioritize.</p>

                <h3>Method Details</h3>
                
                <div class="method-details">
                    <div class="method-card">
                        <h4>RL-PPO</h4>
                        <p>Proximal Policy Optimization implementation based on <a href="https://docs.cleanrl.dev/" target="_blank">CleanRL</a>. Trained for 1M environment steps. Policy takes state vectors as input.</p>
                    </div>

                    <div class="method-card">
                        <h4>RL-SAC</h4>
                        <p>Soft Actor-Critic implementation based on <a href="https://docs.cleanrl.dev/" target="_blank">CleanRL</a>. Trained for 1M environment steps. Policy takes state vectors as input.</p>
                    </div>

                    <div class="method-card">
                        <h4>Diffusion Policy</h4>
                        <p>Diffusion Policy implementation based on <a href="https://github.com/huggingface/lerobot" target="_blank">LeRobot</a>. Trained with 110-115 demonstrations per environment. Policy takes images as input.</p>
                    </div>

                    <div class="method-card">
                        <h4>LLM Planning</h4>
                        <p>LLM planning with given parameterized skills. We use GPT-5. States are given as dictionaries mapping objects to features to values.</p>
                    </div>

                    <div class="method-card">
                        <h4>VLM Planning</h4>
                        <p>VLM planning with given parameterized skills. We use GPT-5. States are given as maps from objects to features to values. Images are also included in the prompt.</p>
                    </div>

                    <div class="method-card">
                        <h4>Bilevel Planning</h4>
                        <p>Search-then-sample bilevel planning with given parameterized skills, operators, predicates, and samplers. States are represented as maps from objects to features to values.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="acknowledgements">
            <div class="container">
                <h2>Acknowledgements</h2>
                <p>We are grateful to Nishanth Kumar and Caelan Garrett for early discussions, and to you, for reviewing this early draft and giving feedback!</p>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 PRBench. All rights reserved.</p>
        </div>
    </footer>

    <script>
        function toggleCollapsible(id) {
            const content = document.getElementById(id);
            const icon = document.getElementById(id.replace('-section', '-toggle'));
            
            if (content.style.maxHeight) {
                content.style.maxHeight = null;
                icon.textContent = '▼';
            } else {
                content.style.maxHeight = content.scrollHeight + 'px';
                icon.textContent = '▲';
            }
        }
    </script>
</body>
</html>

